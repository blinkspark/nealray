{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, layers, applications\n",
    "import os, os.path as path, sys\n",
    "import pandas as pd, numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "Sequence = tf.keras.utils.Sequence\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = 'o:/temp/pixiv/training/'\n",
    "# if len(sys.argv) > 1:\n",
    "#     workingDir = sys.argv[1]\n",
    "imgSize = (112, 112)\n",
    "inputShape = (112, 112, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGAN(Model):\n",
    "\n",
    "    def __init__(self, latent_dim=128, img_shape=inputShape):\n",
    "        super(MyGAN, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "\n",
    "    # def save(self, targetDir):\n",
    "    #     self.generator.save(path.join(targetDir, 'generator.h5'))\n",
    "    #     self.discriminator.save(path.join(targetDir, 'discriminator.h5'))\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(self.latent_dim)),\n",
    "            layers.Dense(7 * 7 * self.latent_dim),\n",
    "            layers.Reshape((7, 7, self.latent_dim)),\n",
    "            layers.Conv2DTranspose(\n",
    "                self.latent_dim * 1, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(\n",
    "                self.latent_dim * 2, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(\n",
    "                self.latent_dim * 3, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(\n",
    "                self.latent_dim * 4, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(\n",
    "                3, kernel_size=3, padding='same', activation='sigmoid')\n",
    "        ],\n",
    "                                 name='generator')\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=self.img_shape),\n",
    "            layers.Conv2D(32, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(64, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(256, kernel_size=3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(256),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ],\n",
    "                                 name='discriminator')\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(MyGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_imgs):\n",
    "        batch_size = tf.shape(real_imgs)[0]\n",
    "        # Sample random points in the latent space\n",
    "        random_numbers = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # Generate a batch of new images\n",
    "        gen_imgs = self.generator(random_numbers)\n",
    "        # combine real and fake images\n",
    "        combined_imgs = tf.concat([real_imgs, gen_imgs], axis=0)\n",
    "        # Labels for generated and real images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)),\n",
    "             tf.zeros((batch_size, 1))], axis=0)\n",
    "        # add random noise to the labels - important!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.discriminator(combined_imgs)\n",
    "            d_loss = self.loss_fn(labels, pred)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_numbers = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # assemble labels for the generator\n",
    "        labels = tf.ones((batch_size, 1))\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.discriminator(self.generator(random_numbers))\n",
    "            g_loss = self.loss_fn(labels, pred)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(grads, self.generator.trainable_variables))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result()\n",
    "        }\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, num_img=3, latent_dim=64):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.rlv = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.rlv is None:\n",
    "\n",
    "            self.rlv = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(self.rlv)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            for i in range(self.num_img):\n",
    "                img = keras.preprocessing.image.array_to_img(\n",
    "                    generated_images[i])\n",
    "                executor.submit(self.save_pic, img, epoch, i)\n",
    "            # save model weights\n",
    "            if epoch % 10 == 0:\n",
    "                self.model.generator.save_weights(\n",
    "                    f'weights/gen_weights_{epoch}.h5')\n",
    "                self.model.discriminator.save_weights(\n",
    "                    f'weights/disc_weights_{epoch}.h5')\n",
    "\n",
    "    def save_pic(self, img, epoch, i):\n",
    "        img.save(\"tmp/generated_img_%03d_%d.jpg\" % (epoch, i), quality=95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "data = pd.read_csv(path.join(workingDir, 'data.csv'), index_col=0)\n",
    "\n",
    "\n",
    "def read_img(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(imgSize)\n",
    "    img = np.asarray(img)\n",
    "    img = img / 255.0\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "\n",
    "img_paths = []\n",
    "with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    for f in os.listdir(path.join(workingDir, 'ds')):\n",
    "        img_paths.append(path.join(workingDir, 'ds', f))\n",
    "    dataset = executor.map(read_img, img_paths)\n",
    "dataset = list(dataset)\n",
    "dataset = np.array(dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100  # In practice, use ~100 epochs\n",
    "\n",
    "gan = MyGAN(latent_dim=64)\n",
    "gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset,\n",
    "    batch_size=40,\n",
    "    # initial_epoch=8,\n",
    "    epochs=epochs,\n",
    "    callbacks=[GANMonitor(num_img=5, latent_dim=64)])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a765c70a93b94e6c6308bc02fe48034fea3f1086e8d50b596d4a63fb95b1ef2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
