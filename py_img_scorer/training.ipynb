{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers, activations\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "trainingDataDir = 'o:/temp/pixiv/training/'\n",
    "targetSize = (224, 224)\n",
    "targetShape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " random_rotation (RandomRota  (None, 224, 224, 3)      0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1311744   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,624,453\n",
      "Trainable params: 2,366,469\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x, filters, kernel_size=3, strides=1, padding='same'):\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides,\n",
    "                      padding=padding)(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides,\n",
    "                      padding=padding)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    x = layers.RandomZoom(height_factor=0.1, width_factor=0.1)(x)\n",
    "    x = layers.RandomFlip()(x)\n",
    "    x = layers.RandomRotation(factor=0.1)(x)\n",
    "    x = layers.Rescaling(scale=1. / 127.5,\n",
    "                         offset=-1,\n",
    "                         input_shape=targetShape)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "appModel = keras.applications.mobilenet_v2.MobileNetV2(include_top=False,\n",
    "                                       weights='imagenet',\n",
    "                                       input_shape=targetShape)\n",
    "appModel.summary()\n",
    "for layer in appModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=targetShape)\n",
    "x = preprocess(inputs)\n",
    "x = appModel(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "# x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(1024)(x)\n",
    "x = layers.Activation(activation=activations.leaky_relu)(x)\n",
    "\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(1024)(x)\n",
    "x = layers.Activation(activation=activations.leaky_relu)(x)\n",
    "\n",
    "x = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    if path.exists('ds.pickle'):\n",
    "        with open('ds.pickle', 'rb') as f:\n",
    "            ds = pickle.load(f)\n",
    "        return ds\n",
    "    else:\n",
    "        df = pd.read_csv(path.join(trainingDataDir, 'data.csv'))\n",
    "        imgs = []\n",
    "        for i in range(len(df)):\n",
    "            img = Image.open(path.join(trainingDataDir, df['img'][i]))\n",
    "            xx = max(img.width, img.height)\n",
    "            new_img = Image.new('RGB', (xx, xx))\n",
    "            new_img.paste(img, (int(\n",
    "                (xx - img.width) / 2), int((xx - img.height) / 2)))\n",
    "            img = new_img.resize(targetSize, Image.BICUBIC)\n",
    "            img = np.array(img)\n",
    "            imgs.append(img)\n",
    "        x = np.array(imgs)\n",
    "        # y = np.array(df['score'].values)\n",
    "        y = []\n",
    "        for v in df['score'].values:\n",
    "            print(v)\n",
    "            row = np.zeros(5)\n",
    "            row[v - 1] = 1\n",
    "            y.append(row)\n",
    "        y = np.array(y)\n",
    "        with open('ds.pickle', 'wb') as f:\n",
    "            pickle.dump((x, y), f)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "(x, y) = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x0000023E62118280>, <keras.layers.preprocessing.image_preprocessing.RandomZoom object at 0x0000023E61F36080>, <keras.layers.preprocessing.image_preprocessing.RandomFlip object at 0x0000023E0008B5B0>, <keras.layers.preprocessing.image_preprocessing.RandomRotation object at 0x0000023E000D3640>, <keras.layers.preprocessing.image_preprocessing.Rescaling object at 0x0000023E3A6CD690>]\n",
      "<keras.engine.functional.Functional object at 0x0000023E3A681FC0>\n",
      "(1, 7, 7, 1280)\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x0000023E00076140>\n",
      "(1, 1280)\n",
      "tf.Tensor(\n",
      "[[1.0709476e-01 6.2304761e-02 1.9141276e-03 ... 1.9315526e+00\n",
      "  1.2785573e-01 0.0000000e+00]], shape=(1, 1280), dtype=float32)\n",
      "<keras.layers.core.dropout.Dropout object at 0x0000023E3A681C30>\n",
      "(1, 1280)\n",
      "tf.Tensor(\n",
      "[[1.0709476e-01 6.2304761e-02 1.9141276e-03 ... 1.9315526e+00\n",
      "  1.2785573e-01 0.0000000e+00]], shape=(1, 1280), dtype=float32)\n",
      "<keras.layers.core.dense.Dense object at 0x0000023E61C49990>\n",
      "(1, 1024)\n",
      "tf.Tensor(\n",
      "[[-0.5117526  -0.02921447 -0.68583465 ... -0.30793762  0.34141183\n",
      "   0.9911163 ]], shape=(1, 1024), dtype=float32)\n",
      "<keras.layers.core.activation.Activation object at 0x0000023E3A64FD60>\n",
      "(1, 1024)\n",
      "tf.Tensor(\n",
      "[[-0.10235053 -0.00584289 -0.13716693 ... -0.06158752  0.34141183\n",
      "   0.9911163 ]], shape=(1, 1024), dtype=float32)\n",
      "[[-1.02350526e-01 -5.84289432e-03 -1.37166932e-01 -1.60750523e-01\n",
      "  -1.52571842e-01  5.80069184e-01  6.54402196e-01  1.65596843e-01\n",
      "   1.14313096e-01 -1.07050836e-02 -1.72328353e-01  6.88420057e-01\n",
      "   2.66979277e-01 -2.32760653e-01  4.44404006e-01  3.22308242e-02\n",
      "   3.29774022e-01  2.18711644e-01  5.09895086e-01 -6.86698034e-02\n",
      "  -1.81714725e-02 -3.25388908e-02  5.62618017e-01 -5.70261502e-04\n",
      "  -5.22181392e-02  1.96718082e-01  6.68841183e-01 -1.45361617e-01\n",
      "   6.90775692e-01 -1.85054570e-01 -1.17470622e-01 -8.27190802e-02\n",
      "  -6.15520142e-02  1.26309067e-01 -3.52339745e-02  4.14521337e-01\n",
      "   2.67601848e-01 -1.38424069e-01  1.64465928e+00  1.18463027e+00\n",
      "  -2.13409811e-01 -1.48663029e-01 -8.33396912e-02  6.38005137e-03\n",
      "  -1.07818000e-01  1.24895573e+00  2.45045766e-01 -3.97901863e-01\n",
      "   1.37401462e-01  8.18899572e-01  7.74323583e-01 -1.31791234e-01\n",
      "   2.40121543e-01  1.22977816e-01  1.36879051e+00 -9.71048996e-02\n",
      "  -9.61657763e-02 -9.98904034e-02 -2.51040369e-01  1.06862831e+00\n",
      "   1.19042248e-01 -4.21197377e-02 -6.32798895e-02 -3.86576690e-02\n",
      "   2.23493838e+00 -1.80498466e-01  1.00468802e+00  3.61105025e-01\n",
      "   8.77255321e-01 -3.18880267e-02  4.35224056e-01 -1.80852577e-01\n",
      "  -1.20416664e-01 -5.75891845e-02  6.67063892e-03  3.80887479e-01\n",
      "  -2.66548004e-02 -3.46783586e-02  2.45506197e-01 -1.74060807e-01\n",
      "   3.54016364e-01  4.29457426e-03 -1.15229204e-01 -1.92917213e-01\n",
      "   5.12768447e-01 -2.44192079e-01  1.91119850e-01  4.35880303e-01\n",
      "  -1.66133640e-03 -2.54400343e-01 -5.59048168e-02  2.55024582e-01\n",
      "   1.53850555e-01 -6.24756590e-02  8.54648829e-01  6.14148974e-01\n",
      "   3.70070368e-01  9.91254270e-01  7.51636028e-02  2.19910234e-01\n",
      "  -5.43834232e-02 -6.20678477e-02 -5.01292013e-02  8.37319255e-01\n",
      "  -1.38486192e-01 -2.28873026e-02 -6.03556298e-02 -8.25982839e-02\n",
      "  -1.76972745e-03 -2.48209829e-03  4.40986216e-01 -1.12613797e-01\n",
      "  -1.89628676e-01  3.90154451e-01  4.60721850e-02 -8.15390125e-02\n",
      "  -6.31573796e-02  3.19517136e-01 -3.17510380e-03  3.42661887e-01\n",
      "   5.41765988e-03  6.18309557e-01  1.02604680e-01 -8.57112110e-02\n",
      "  -3.21444087e-02 -1.61339030e-01  6.34693682e-01  2.77966797e-01\n",
      "  -9.16960463e-02  1.66082692e+00 -1.41899828e-02  8.92855823e-02\n",
      "   4.23983634e-01  8.29759717e-01  6.45172000e-01 -7.99144134e-02\n",
      "   5.94677448e-01  1.30461156e-01  1.21567702e+00 -3.44913453e-01\n",
      "  -2.09749699e-01  6.54878974e-01 -8.29067528e-02 -1.20286062e-01\n",
      "  -1.85285524e-01  7.09575862e-02 -1.89322039e-01 -1.82610098e-02\n",
      "   8.02689373e-01 -8.95709619e-02 -5.59857523e-04 -2.74727404e-01\n",
      "   1.97245479e-02  4.88871992e-01 -3.70387733e-02  4.16975707e-01\n",
      "  -9.73698646e-02  2.08306313e-03 -1.35867670e-01  5.90016305e-01\n",
      "   2.18056142e-01 -5.13009727e-02  6.24717474e-02  1.85400903e-01\n",
      "  -5.52104674e-02 -4.33460809e-02 -5.97405210e-02  4.21094745e-01\n",
      "   3.44175786e-01  9.34757590e-01 -2.57757336e-01  4.56730723e-01\n",
      "   5.00842184e-02  8.06144357e-01  2.79046655e-01 -1.17137544e-01\n",
      "   1.16185069e-01  3.66737127e-01  6.12034082e-01  1.40617299e+00\n",
      "  -5.62399738e-02 -1.36928558e-02  6.46837950e-01  1.26538381e-01\n",
      "  -9.99337509e-02  7.82081187e-01  8.28218460e-01 -1.22831903e-01\n",
      "   7.26346552e-01 -1.73780829e-01 -1.13677166e-01  7.17420578e-02\n",
      "  -1.15719453e-01 -8.86035562e-02  5.06269455e-01 -1.07926510e-01\n",
      "   7.30572224e-01  3.68697464e-01 -7.13695213e-02 -1.14990763e-01\n",
      "   1.32309246e+00 -1.02218069e-01 -8.70159268e-02  2.11003828e+00\n",
      "  -3.65810208e-02 -5.14982119e-02 -7.07181618e-02 -4.49665599e-02\n",
      "   5.58105588e-01 -7.34064132e-02  4.62429672e-01 -4.81312349e-02\n",
      "   3.09318483e-01 -1.75438106e-01 -1.51862681e-01 -3.79387110e-01\n",
      "  -1.67059436e-01  1.25128484e+00 -6.46736026e-02  1.08410275e+00\n",
      "  -7.88560137e-02 -1.21584415e-01  1.32385504e+00 -2.85130143e-02\n",
      "  -6.24712966e-02 -1.39178410e-01  7.92194664e-01  4.12457883e-01\n",
      "  -2.00132723e-03  5.93651712e-01 -7.17726499e-02 -1.82831705e-01\n",
      "  -8.85501504e-02  2.45371908e-01 -1.28861070e-01 -1.16811814e-02\n",
      "  -9.20852050e-02 -1.56960770e-01 -2.07722574e-01  1.51091552e+00\n",
      "  -4.11716104e-02  1.67585060e-01  7.01959610e-01 -4.34136540e-02\n",
      "   2.82273233e-01 -3.89146321e-02  1.70304939e-01  1.16554439e+00\n",
      "  -7.60515109e-02  2.55488008e-01  3.10735375e-01 -1.04892194e-01\n",
      "  -1.47531033e-01 -1.32090837e-01  8.87497663e-01 -2.82702502e-02\n",
      "  -1.05902031e-01  6.54393613e-01 -1.81930408e-01 -6.78831665e-03\n",
      "   2.71569908e-01  5.67087531e-02 -1.28917739e-01 -1.31190166e-01\n",
      "  -6.10533617e-02 -2.01587543e-01 -1.92867443e-01  1.16957092e+00\n",
      "  -2.08012924e-01  4.72014219e-01 -1.88149318e-01 -9.80180502e-02\n",
      "  -3.31114642e-02 -1.06611326e-01 -9.84235927e-02 -1.16770463e-02\n",
      "   5.17882943e-01  1.04918683e+00  1.01659036e+00  3.72597277e-01\n",
      "   1.72631264e-01  9.32026684e-01  4.56700981e-01 -4.94795926e-02\n",
      "   1.17649615e+00  8.97645235e-01 -2.21808199e-02 -1.20504200e-01\n",
      "  -1.38150156e-03  8.63882661e-01 -3.82731050e-01 -7.46197477e-02\n",
      "   1.07829845e+00  4.89206731e-01 -4.97883745e-02 -7.04767853e-02\n",
      "   2.82792777e-01 -9.30107459e-02  1.44210768e+00  1.04678869e-01\n",
      "   4.39443886e-01  9.36777294e-01 -8.72241259e-02 -8.81440416e-02\n",
      "  -1.97247818e-01  5.70364714e-01  4.64410722e-01  2.43119359e-01\n",
      "  -5.64757586e-02 -3.60024534e-02  1.02329707e+00  6.11868978e-01\n",
      "  -2.16456175e-01 -4.01674919e-02 -6.76769838e-02 -2.73592293e-01\n",
      "   2.17254564e-01 -4.75986563e-02  1.39164853e+00 -2.83235665e-02\n",
      "  -6.90285638e-02 -4.27840054e-02  7.49392956e-02 -2.26201683e-01\n",
      "  -3.24386619e-02  8.62181008e-01 -1.99901890e-02  7.15678811e-01\n",
      "  -1.53483555e-01 -2.48574372e-02  5.09126544e-01  4.25225981e-02\n",
      "   7.99898148e-01  8.72769773e-01  1.56441748e-01  8.73843193e-01\n",
      "   4.58825439e-01  1.45678878e-01 -7.56896511e-02  7.83096850e-01\n",
      "  -2.14372680e-01  1.15716290e+00 -8.56856778e-02  7.84998536e-02\n",
      "   7.10521102e-01  6.15239680e-01  7.29247332e-02  1.03117967e+00\n",
      "  -2.17430025e-01 -8.53296593e-02 -1.18408538e-01  3.40795875e-01\n",
      "   1.17294836e+00  1.02845997e-01  4.32676405e-01 -2.11947272e-03\n",
      "  -5.10367146e-03  2.94339776e-01  3.64926755e-01  5.32401383e-01\n",
      "   2.67228842e-01  7.21516609e-01  4.39634472e-01  1.51538327e-02\n",
      "   8.02801073e-01  5.08479536e-01  3.04334238e-02  4.59017754e-02\n",
      "   3.05716842e-02 -1.43802494e-01  1.96967006e-01  2.62563378e-02\n",
      "  -2.14845046e-01 -1.16002478e-01 -8.52114707e-02 -1.09736323e-02\n",
      "   5.15737414e-01  1.41282260e-01 -1.01150744e-01 -6.20611906e-02\n",
      "   1.26149738e+00 -3.69169824e-02  2.91936427e-01  5.92050552e-02\n",
      "  -2.52957731e-01 -1.60353318e-01 -1.05089270e-01 -1.67885378e-01\n",
      "  -3.13710533e-02 -4.94361296e-02 -9.69070494e-02 -1.21758819e-01\n",
      "   4.70999897e-01  1.12186089e-01 -3.32596898e-02 -2.89358109e-01\n",
      "  -2.04670951e-01  6.05891168e-01  7.49206781e-01 -2.35749017e-02\n",
      "   1.17786661e-01  7.45151997e-01  1.18600261e+00  9.06561255e-01\n",
      "   1.26427308e-01 -1.18701600e-01  1.05892196e-02 -1.00237884e-01\n",
      "  -1.96143761e-01  1.50280344e+00 -1.37696296e-01 -1.02620302e-02\n",
      "   3.57393384e-01 -1.11667745e-01 -1.85101077e-01  4.95169163e-02\n",
      "   2.52205580e-01 -1.10983804e-01 -7.42864534e-02 -2.08184011e-02\n",
      "   1.08289875e-01 -2.06179291e-01  4.68412101e-01 -2.22381696e-01\n",
      "  -1.06198668e-01 -2.15334520e-01  1.82980552e-01 -2.20634371e-01\n",
      "  -6.71290681e-02 -7.28985816e-02 -1.57603264e-01 -1.65053608e-03\n",
      "  -1.54696107e-01  2.70351261e-01 -4.85948585e-02 -2.20019862e-01\n",
      "   1.91263020e-01  2.99785465e-01  2.57460743e-01 -3.43692005e-02\n",
      "   5.54944098e-01 -6.15439713e-02 -1.81218833e-01  5.45394123e-01\n",
      "  -5.27529381e-02  1.54801935e-01 -4.19471525e-02 -5.63422625e-04\n",
      "  -5.89925908e-02  1.26666451e+00 -8.98692831e-02 -3.40900430e-03\n",
      "   6.57597661e-01  7.94122159e-01  1.09224722e-01  1.07992148e+00\n",
      "   8.38527918e-01 -5.89429252e-02  3.48206490e-01  1.19461119e-01\n",
      "  -4.23334800e-02 -4.46763001e-02  1.97547674e-03  9.83524203e-01\n",
      "   7.90675521e-01 -9.17288288e-02  2.90812671e-01  3.07773352e-01\n",
      "   8.84358823e-01 -1.01261020e-01 -4.77390364e-02 -2.60008909e-02\n",
      "  -5.51048527e-03  5.23563027e-02 -1.14399277e-01 -1.23498060e-01\n",
      "  -1.87297165e-01 -3.06398690e-01  1.39258519e-01 -6.33585453e-02\n",
      "   1.98352039e-01  1.68880969e-01 -1.38307676e-01  9.18967843e-01\n",
      "  -1.24887705e-01 -8.12933128e-03  1.28902048e-01  4.55483973e-01\n",
      "   2.26319641e-01 -3.52052459e-03 -2.04068705e-01  1.71509147e-01\n",
      "  -8.31453223e-03 -7.68204033e-02 -3.12053747e-02 -1.33214956e-02\n",
      "  -2.01835990e-01 -1.17916182e-01  3.31127882e-01 -1.36767313e-01\n",
      "  -4.53957580e-02 -1.25575230e-01 -3.85530107e-02 -4.87781037e-03\n",
      "   6.60009325e-01  1.07175156e-01 -6.21729381e-02 -2.51278523e-02\n",
      "   6.12508655e-01  3.21023405e-01  7.12241769e-01 -1.86694860e-02\n",
      "  -1.10879496e-01 -2.89650746e-02  1.15148604e-01 -6.20371243e-03\n",
      "  -3.35058570e-02 -1.29915893e-01  7.02247620e-01  2.06111848e-01\n",
      "   7.03733206e-01 -1.07952707e-01  7.60067701e-01 -7.65457377e-02\n",
      "   4.82402414e-01 -8.00926238e-02 -1.58121679e-02 -1.13841109e-01\n",
      "   4.94350553e-01  1.29514754e-01  2.61932760e-01 -6.17266111e-02\n",
      "  -1.95722729e-01  2.23791704e-01 -3.39990860e-04 -3.89160998e-02\n",
      "   8.88044715e-01 -5.16947173e-02  5.16572654e-01  4.34996635e-01\n",
      "  -3.27688158e-02  2.42921114e-01  6.06713772e-01 -8.13648850e-02\n",
      "  -1.81468651e-01  1.21293151e+00 -2.97151536e-01 -7.94919282e-02\n",
      "   1.43345594e-02 -9.31146666e-02 -2.80581594e-01 -1.23452835e-01\n",
      "   6.30598545e-01 -3.26374054e-01 -2.00769335e-01  4.73101676e-01\n",
      "   1.18857634e+00  1.66877413e+00 -4.46902774e-02  6.39033556e-01\n",
      "  -2.56520510e-03 -1.35629745e-02  6.19662941e-01  4.90755498e-01\n",
      "  -1.10974684e-01  6.30540401e-02  8.50636899e-01  4.24363434e-01\n",
      "  -5.88306673e-02  6.88104272e-01 -8.56453702e-02 -9.38459784e-02\n",
      "   2.18389079e-01 -7.97046348e-02 -9.75413062e-03 -9.11695436e-02\n",
      "  -3.46953282e-03 -5.74504621e-02  6.06096864e-01  4.15682018e-01\n",
      "  -1.67523235e-01 -8.91844630e-02  5.41474938e-01 -5.15633710e-02\n",
      "  -3.74870785e-02  4.81722206e-02 -7.32441694e-02  5.40037692e-01\n",
      "   1.02846026e+00 -4.72202413e-02  6.55748904e-01 -6.18048422e-02\n",
      "  -6.47055684e-03  4.29908156e-01 -1.23321965e-01 -2.53014535e-01\n",
      "   1.47896886e-01  4.72240865e-01  6.41929209e-01 -1.06123112e-01\n",
      "  -2.24580482e-01  5.61281204e-01 -2.18347743e-01  3.35132658e-01\n",
      "  -1.73560694e-01 -5.20182736e-02 -3.54661793e-01  8.96723390e-01\n",
      "   3.00277889e-01  4.11280870e-01 -8.55038781e-03 -1.89209934e-02\n",
      "   1.16460741e+00 -9.21008885e-02  2.54194677e-01 -9.54676494e-02\n",
      "   4.01194036e-01  1.11107957e+00 -1.30308628e-01 -1.10710762e-01\n",
      "  -8.21698904e-02 -1.30112216e-01 -5.14886677e-02  2.46233478e-01\n",
      "   2.16445088e-01  8.40563834e-01  2.56582260e-01  2.73677260e-01\n",
      "   6.56192541e-01  3.17563891e-01 -2.67033994e-01 -1.16517775e-01\n",
      "   1.05768454e+00 -1.20604396e-01 -8.13457370e-02  4.97738570e-02\n",
      "   4.94446844e-01  8.00303400e-01 -1.13372706e-01  3.93655241e-01\n",
      "  -1.58200964e-01  2.15989411e-01 -1.19310562e-02 -2.04025015e-01\n",
      "   4.41320002e-01  8.38519454e-01 -5.82603924e-02  7.18061209e-01\n",
      "   5.80670357e-01 -7.00782910e-02  1.50395930e-01  7.01163530e-01\n",
      "   8.25002432e-01  7.75182843e-01  2.36209124e-01 -4.48380485e-02\n",
      "   1.88707411e-01  4.04768229e-01  1.20593309e-01  4.66471434e-01\n",
      "  -5.34883030e-02 -5.48232086e-02 -2.25539729e-01 -8.32302794e-02\n",
      "  -8.68694335e-02  7.06083119e-01 -2.70972196e-02 -2.69784629e-01\n",
      "   1.57668024e-01  2.90829837e-02  7.64537930e-01 -3.31349045e-01\n",
      "  -2.64081489e-02 -1.08984476e-02  1.84896573e-01 -3.23337317e-02\n",
      "  -6.70250086e-03  4.09160465e-01 -1.55180683e-02 -1.77443251e-01\n",
      "  -1.75903231e-01  4.02410418e-01  1.57157660e-01 -1.66739404e-01\n",
      "  -1.80853412e-01  3.65522683e-01  4.21217680e-01 -2.85924166e-01\n",
      "  -1.56369627e-01 -1.06149493e-02  6.30563676e-01 -4.58105803e-02\n",
      "  -1.76371679e-01 -1.72356531e-01 -1.31251082e-01  4.43736672e-01\n",
      "   5.83697379e-01 -3.38100158e-02 -1.08680665e-01  5.99776506e-02\n",
      "   2.33884156e-02 -1.08178370e-01  2.47892603e-01  4.14521277e-01\n",
      "   4.03959602e-01  4.62967426e-01 -2.40245864e-01 -5.24864681e-02\n",
      "   7.58555412e-01 -1.59992605e-01  1.72464699e-01  1.12535691e+00\n",
      "  -9.57497880e-02 -7.23155513e-02  6.70676589e-01 -7.07011968e-02\n",
      "   7.49612093e-01 -7.45155513e-02 -6.49247989e-02  1.29881692e+00\n",
      "  -7.02700317e-02 -9.58257541e-02 -4.93214540e-02  1.03159642e+00\n",
      "  -2.01908350e-02  1.29244304e+00 -1.83812901e-01  1.21129251e+00\n",
      "   6.19388700e-01 -2.08539650e-01  7.82925963e-01  1.44331396e-01\n",
      "  -8.34864900e-02  3.43167931e-02  5.90623498e-01 -6.62021935e-02\n",
      "   1.02509296e+00  6.15876853e-01  1.59653187e+00 -1.19835787e-01\n",
      "  -1.40936553e-01  8.23532283e-01 -9.12681520e-02 -6.57634661e-02\n",
      "   1.39066607e-01  9.35055614e-02 -2.00334504e-01  1.26890969e+00\n",
      "  -1.69726852e-02 -1.70168504e-01  1.80872291e-01  4.35710669e-01\n",
      "   1.81559652e-01  4.48340356e-01 -5.77389300e-02  4.29006368e-01\n",
      "  -3.16101760e-02 -2.98824102e-01  1.16250491e+00  8.46429884e-01\n",
      "  -8.12518969e-02  1.78305197e+00  5.82530320e-01 -1.55460522e-01\n",
      "   4.39882785e-01  2.76002645e-01  2.56991714e-01 -1.55035019e-01\n",
      "  -1.89954087e-01 -4.81952690e-02 -9.52323750e-02  6.60522163e-01\n",
      "   1.37355244e+00 -5.19149378e-02  1.03006840e-01  4.28109556e-01\n",
      "  -1.59744862e-02  2.44263455e-01 -2.60949433e-02 -1.01256371e-02\n",
      "   1.42878592e-02  1.20250773e+00  3.38112742e-01  1.03613466e-01\n",
      "  -7.76427984e-03  8.35693553e-02  1.97140113e-01  2.32002944e-01\n",
      "  -4.11528945e-02  4.10651177e-01 -2.52883742e-03 -8.65405276e-02\n",
      "   1.32896215e-01  4.30708140e-01  4.07360017e-01 -1.23719811e-01\n",
      "   5.87496281e-01  3.90875787e-02  1.04997069e-01 -1.22193158e-01\n",
      "  -1.84279114e-01  1.39705613e-01 -1.35337517e-01  1.43065882e+00\n",
      "   8.52011204e-01 -2.90995724e-02 -2.02726156e-01 -1.73106696e-02\n",
      "   8.04194584e-02  1.86429113e-01 -3.28866206e-02 -4.25004736e-02\n",
      "   5.71448430e-02 -7.35151172e-02 -7.66322836e-02  7.71575570e-02\n",
      "  -1.77514032e-01  1.81827933e-01 -2.76298802e-02  6.74732327e-01\n",
      "  -1.39448717e-01  5.33352345e-02  9.27959442e-01  1.14763212e+00\n",
      "  -1.62060052e-01 -3.00789811e-02 -1.48529233e-02 -2.12362513e-01\n",
      "   3.55280161e-01  1.20271993e+00 -2.46054798e-01 -1.32291272e-01\n",
      "  -5.08136451e-02  3.07934910e-01 -2.60633081e-01  2.01747343e-01\n",
      "   8.05413127e-01 -7.92595297e-02 -9.59913880e-02 -3.82164791e-02\n",
      "  -8.25876445e-02 -1.96255833e-01 -7.58354887e-02 -3.13374065e-02\n",
      "   8.03535938e-01  5.40598333e-01  9.13358629e-02 -3.20256166e-02\n",
      "  -1.94036230e-01 -1.53818682e-01 -1.58938449e-02  5.93950152e-01\n",
      "   1.53664565e+00 -2.04866216e-01 -7.55725754e-03  8.24815273e-01\n",
      "  -2.15070754e-01 -1.45069614e-01  2.72302032e-01 -7.00830147e-02\n",
      "  -3.85147445e-02 -1.52995780e-01 -2.41878033e-02 -5.95365791e-03\n",
      "   5.94204307e-01  8.20234179e-01  3.33033293e-01  4.24003541e-01\n",
      "  -8.53214189e-02 -2.34220907e-01  9.36256275e-02  1.55567154e-01\n",
      "  -8.38557482e-02 -7.01547340e-02 -1.21141650e-01  1.23156798e+00\n",
      "   1.86593682e-01  1.72922444e+00  4.22732413e-01 -3.75850163e-02\n",
      "   3.96486968e-02  4.35389638e-01 -1.44199459e-02  6.95623994e-01\n",
      "   5.13238013e-01  8.10490966e-01  1.57786608e+00  7.44601488e-02\n",
      "  -2.88617074e-01  6.94606304e-01  4.22081828e-01 -1.12839475e-01\n",
      "   5.11847854e-01 -9.57308188e-02 -3.23037654e-02 -1.54391870e-01\n",
      "   3.15624774e-02 -1.54799297e-01 -3.26409526e-02  2.77733207e-02\n",
      "  -5.59869483e-02  6.20391071e-01 -1.06822532e-02 -1.15730263e-01\n",
      "  -1.10981181e-01 -1.28808024e-03 -2.27696188e-02  3.12322468e-01\n",
      "   1.91023558e-01  2.48372555e-04 -8.46841484e-02 -5.52763119e-02\n",
      "  -2.83089075e-02 -7.76332021e-02  5.36465645e-01 -1.89232603e-01\n",
      "   9.98078465e-01 -1.82241306e-01  1.19178891e-01 -1.09172560e-01\n",
      "  -5.10874167e-02 -1.98903069e-01 -1.44011125e-01  6.07578874e-01\n",
      "  -5.38439043e-02 -2.21780129e-02  9.26550567e-01  6.40182644e-02\n",
      "   1.04444766e+00 -1.06852986e-01 -2.53468286e-02  7.65874505e-01\n",
      "  -1.36129186e-01 -4.19373736e-02 -3.24675217e-02  2.48113364e-01\n",
      "   1.21845949e+00 -7.97363520e-02  1.21673691e+00 -1.31883904e-01\n",
      "   4.60542142e-01 -7.39038959e-02 -3.18071336e-01 -1.41257331e-01\n",
      "   9.38796401e-01  1.92198098e-01  5.01412034e-01 -1.72839984e-01\n",
      "  -6.28307909e-02 -1.46998927e-01  5.23321509e-01  1.20963764e+00\n",
      "   1.18159652e-02  9.25509930e-01  5.27845263e-01 -1.90978244e-01\n",
      "  -1.48172257e-02  4.86913413e-01  2.22575283e+00  1.45963442e+00\n",
      "   3.40050817e-01 -2.51871914e-01 -7.57088214e-02  2.54001319e-01\n",
      "  -8.44817311e-02  7.76710510e-02  1.35592604e+00 -1.33706078e-01\n",
      "  -8.00978765e-02  5.33727705e-01 -2.32730106e-01  8.36569130e-01\n",
      "  -1.10581718e-01  1.69064391e+00  7.39157557e-01 -9.83299762e-02\n",
      "  -1.53557062e-01 -2.95086354e-01  2.27121651e-01 -2.60558993e-01\n",
      "   5.60829163e-01  4.12298530e-01 -4.52759443e-03  3.13665450e-01\n",
      "   5.19031473e-02  7.35532045e-01  2.20766336e-01 -1.44597203e-01\n",
      "   5.28706312e-01 -1.57834627e-02  1.24418139e-02  1.20883428e-01\n",
      "   6.98706210e-01  4.76874113e-02 -3.08053382e-02  1.20228082e-01\n",
      "   2.02490300e-01  2.56516755e-01  6.09436631e-01 -2.40660626e-02\n",
      "  -1.63323328e-01 -4.88666385e-01 -1.56974301e-01 -5.76285534e-02\n",
      "   9.17225361e-01 -1.09552264e-01  2.08459288e-01  4.39304769e-01\n",
      "  -1.08148836e-01  2.84168810e-01  5.01337767e-01  5.08008540e-01\n",
      "   5.93755096e-02  9.71285403e-01 -7.17922449e-02 -2.58845747e-01\n",
      "  -1.66301355e-01 -8.69730562e-02  2.22563446e-01 -8.03539380e-02\n",
      "   1.01671994e+00 -6.15875237e-02  3.41411829e-01  9.91116285e-01]]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(model.layers[:5])\n",
    "dx = model.layers[1](x[:1])\n",
    "# plt.imshow(tf.reshape(tf.cast(dx, tf.uint8), targetShape))\n",
    "# plt.show()\n",
    "dx = model.layers[2](dx)\n",
    "# plt.imshow(tf.reshape(tf.cast(dx, tf.uint8), targetShape))\n",
    "# plt.show()\n",
    "dx = model.layers[3](dx)\n",
    "# plt.imshow(tf.reshape(tf.cast(dx, tf.uint8), targetShape))\n",
    "# plt.show()\n",
    "dx = model.layers[4](dx)\n",
    "# plt.imshow(tf.reshape(tf.cast(dx, tf.uint8), targetShape))\n",
    "# plt.show()\n",
    "print(model.layers[5])\n",
    "dx = model.layers[5](dx)\n",
    "print(dx.shape)\n",
    "print(model.layers[6])\n",
    "dx = model.layers[6](dx)\n",
    "print(dx.shape)\n",
    "print(dx)\n",
    "print(model.layers[7])\n",
    "dx = model.layers[7](dx)\n",
    "print(dx.shape)\n",
    "print(dx)\n",
    "print(model.layers[8])\n",
    "dx = model.layers[8](dx)\n",
    "print(dx.shape)\n",
    "print(dx)\n",
    "print(model.layers[9])\n",
    "dx = model.layers[9](dx)\n",
    "print(dx.shape)\n",
    "print(dx)\n",
    "dx = np.array(dx)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 5s 96ms/step - loss: 3.9461 - accuracy: 0.3995 - val_loss: 1.3631 - val_accuracy: 0.3846\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 1.3909 - accuracy: 0.4773 - val_loss: 1.7425 - val_accuracy: 0.4231\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 2s 68ms/step - loss: 1.3423 - accuracy: 0.4790 - val_loss: 1.4434 - val_accuracy: 0.3590\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 2s 68ms/step - loss: 1.1708 - accuracy: 0.5201 - val_loss: 2.6045 - val_accuracy: 0.3487\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 2s 67ms/step - loss: 1.1559 - accuracy: 0.5577 - val_loss: 2.1178 - val_accuracy: 0.3385\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 2s 68ms/step - loss: 1.0949 - accuracy: 0.5731 - val_loss: 1.6763 - val_accuracy: 0.3487\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 1.0142 - accuracy: 0.5894 - val_loss: 1.8332 - val_accuracy: 0.4282\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 1.0291 - accuracy: 0.5749 - val_loss: 1.5886 - val_accuracy: 0.4513\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 0.8915 - accuracy: 0.6039 - val_loss: 1.2964 - val_accuracy: 0.4974\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 2s 68ms/step - loss: 0.9156 - accuracy: 0.6476 - val_loss: 2.4842 - val_accuracy: 0.3205\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.8919 - accuracy: 0.6305 - val_loss: 1.3101 - val_accuracy: 0.4846\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 0.8844 - accuracy: 0.6202 - val_loss: 1.7194 - val_accuracy: 0.4231\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.8694 - accuracy: 0.6330 - val_loss: 1.5647 - val_accuracy: 0.4462\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 4s 93ms/step - loss: 0.8075 - accuracy: 0.6775 - val_loss: 1.5120 - val_accuracy: 0.4513\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 0.8134 - accuracy: 0.6561 - val_loss: 2.5540 - val_accuracy: 0.4128\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 0.7570 - accuracy: 0.6878 - val_loss: 2.0887 - val_accuracy: 0.3897\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 0.7552 - accuracy: 0.6980 - val_loss: 1.9221 - val_accuracy: 0.4538\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.8085 - accuracy: 0.6818 - val_loss: 2.1807 - val_accuracy: 0.3872\n",
      "Epoch 19/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.7581 - accuracy: 0.6866Restoring model weights from the end of the best epoch: 9.\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 0.7581 - accuracy: 0.6843 - val_loss: 1.6463 - val_accuracy: 0.4487\n",
      "Epoch 19: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e3d2eff10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                  patience=10,\n",
    "                                  verbose=1,\n",
    "                                  restore_best_weights=True),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    x,\n",
    "    y,\n",
    "    callbacks=cbs,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01609944 0.04677213 0.6258664  0.2796855  0.03157651]] 3\n"
     ]
    }
   ],
   "source": [
    "def predict(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    xx = max(img.width, img.height)\n",
    "    new_img = Image.new('RGB', (xx, xx))\n",
    "    new_img.paste(img, (int((xx - img.width) / 2), int((xx - img.height) / 2)))\n",
    "    img = new_img.resize(targetSize, Image.BICUBIC)\n",
    "    img = np.array(img)\n",
    "    img = img.reshape((1, 224, 224, 3))\n",
    "    return model.predict(img)\n",
    "\n",
    "\n",
    "pred = predict(path.join('o:/temp/pixiv/test/', '96284448_p0.jpg'))\n",
    "pred_score = np.argmax(pred) + 1\n",
    "print(pred, pred_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a765c70a93b94e6c6308bc02fe48034fea3f1086e8d50b596d4a63fb95b1ef2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
